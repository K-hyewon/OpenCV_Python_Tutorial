{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations on Images\n",
    "\n",
    "## Goal\n",
    "\n",
    "Learn to:\n",
    "\n",
    "* Access pixel values and modify them\n",
    "* Access image properties\n",
    "* Setting Region of Image (ROI)\n",
    "* Splitting and Merging images\n",
    "\n",
    "Almost all the operations in this section is mainly related to **Numpy** rather than OpenCV. A good knowledge of **Numpy** is required to write better optimized code with OpenCV.\n",
    "\n",
    "(Examples will be shown in Python terminal since most of them are just single line codes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing and Modifying pixel values\n",
    "\n",
    "Letâ€™s load a color image first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('data/messi5.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access a pixel value by its row and column coordinates. For BGR image, it returns an array of Blue, Green, Red values. For grayscale image, just corresponding intensity is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156 166 200]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([156, 166, 200], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = img[100,100]\n",
    "print(px)\n",
    "px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing only blue pixel\n",
    "blue = img[100,100,0]\n",
    "print(blue)\n",
    "blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify the pixel values the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "img[100,100] = [255,255,255]\n",
    "print(img[100,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Warning\n",
    ">\n",
    "> Numpy is a optimized library *for fast array calculations*. So simply accessing each and every pixel values and modifying it will be very slow and it is discouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Note\n",
    ">\n",
    "> Above mentioned method is normally used for selecting a region of array, say first 5 rows and last 3 columns like that. For individual pixel access, **Numpy** array methods, `array.item()` and `array.itemset()` is considered to be better. But it always returns a scalar. So if you want to access all B,G,R values, you need to call `array.item()` separately for all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better pixel accessing and editing method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing RED value\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modifying RED value\n",
    "img.itemset((10,10,2),100)\n",
    "img.item(10,10,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Image Properties\n",
    "\n",
    "Image properties include \n",
    "* number of rows, columns and channels, \n",
    "* type of image data, \n",
    "* number of pixels \n",
    "* etc.\n",
    "\n",
    "Shape of image is accessed by `img.shape`. \n",
    "* It returns a tuple of number of rows, columns and channels (if image is color):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 548, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Note\n",
    ">\n",
    "> If image is grayscale, tuple returned contains only number of rows and columns. So it is a good method to check if loaded image is grayscale or color image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of pixels is accessed by `img.size`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562248\n"
     ]
    }
   ],
   "source": [
    "print(img.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image datatype is obtained by `img.dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Note\n",
    ">\n",
    ">img.dtype is very important while debugging because a large number of errors in OpenCV-Python code is caused by invalid datatype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image ROI\n",
    "\n",
    "Sometimes, you will have to play with certain region of images. For eye detection in images, first perform face detection over the image until the face is found, then search within the face region for eyes. This approach improves accuracy (because eyes are always on faces :D ) and performance (because we search for a small area)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROI** is again obtained using **Numpy indexing**. \n",
    "Here I am selecting the ball and copying it to another region in the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original imgae',img) #expects true color\n",
    "\n",
    "ball = img[280:340,330:390]\n",
    "img[273:333,100:160] = ball\n",
    "\n",
    "cv2.imshow('modified image',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Merging Image Channels\n",
    "\n",
    "The B,G,R channels of an image can be split into their individual planes when needed. Then, the individual channels can be merged back together to form a BGR image again. This can be performed by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)\n",
    "img = cv2.merge((b,g,r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('blue channel img',b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, you want to make all the red pixels to zero, you need not split like this and put it equal to zero. You can simply use Numpy indexing which is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,:,2]= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('zero red channel img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Warning\n",
    ">\n",
    "> `cv2.split()` is a costly operation (in terms of time), so only use it if necessary. Numpy indexing is much more efficient and should be used if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Borders for Images (Padding)\n",
    "\n",
    "If you want to create a border around the image, something like a photo frame, you can use `cv2.copyMakeBorder()` function. But it has **more applications for convolution operation**, zero padding etc. This function takes following arguments:\n",
    "\n",
    "* src - input image\n",
    "* top, bottom, left, right - border width in number of pixels in corresponding directions\n",
    "* borderType - Flag defining what kind of border to be added. It can be following types:\n",
    "    * **cv2.BORDER_CONSTANT** - Adds a constant colored border. The value should be given as next argument.\n",
    "    * **cv2.BORDER_REFLECT** - Border will be mirror reflection of the border elements, like this : fedcba|abcdefgh|hgfedcb\n",
    "    * **cv2.BORDER_REFLECT_101** or `cv2.BORDER_DEFAULT` - Same as above, but with a slight change, like this : gfedcb|abcdefgh|gfedcba\n",
    "    * **cv2.BORDER_REPLICATE** - Last element is replicated throughout, like this: aaaaaa|abcdefgh|hhhhhhh\n",
    "    * **cv2.BORDER_WRAP** - Canâ€™t explain, it will look like this : cdefgh|abcdefgh|abcdefg\n",
    "* value - Color of border if border type is `cv2.BORDER_CONSTANT`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sample code demonstrating all these border types for better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8343365bacf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mBLUE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "BLUE = [255,0,0]\n",
    "\n",
    "img1 = cv2.imread('opencv_logo.png')\n",
    "\n",
    "replicate = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REPLICATE)\n",
    "reflect = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT)\n",
    "reflect101 = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_REFLECT_101)\n",
    "wrap = cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_WRAP)\n",
    "constant= cv2.copyMakeBorder(img1,10,10,10,10,cv2.BORDER_CONSTANT,value=BLUE)\n",
    "\n",
    "plt.subplot(231),plt.imshow(img1,'gray'),plt.title('ORIGINAL')\n",
    "plt.subplot(232),plt.imshow(replicate,'gray'),plt.title('REPLICATE')\n",
    "plt.subplot(233),plt.imshow(reflect,'gray'),plt.title('REFLECT')\n",
    "plt.subplot(234),plt.imshow(reflect101,'gray'),plt.title('REFLECT_101')\n",
    "plt.subplot(235),plt.imshow(wrap,'gray'),plt.title('WRAP')\n",
    "plt.subplot(236),plt.imshow(constant,'gray'),plt.title('CONSTANT')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the result above. (Image is displayed with matplotlib. So RED and BLUE planes will be interchanged):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
