{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Original.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mjc_g89rFP"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEPEeBRa8CbI"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOLK-PiS9xPu"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFpp1BjG8GE3"
      },
      "source": [
        "# to get the files in proper order\n",
        "def sorted_alphanumeric(data):  \n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
        "    return sorted(data,key = alphanum_key)\n",
        "# defining the size of the image\n",
        "SIZE = 256\n",
        "high_img = []\n",
        "path = '../input/image-super-resolution/dataset/Raw Data/high_res'\n",
        "files = os.listdir(path)\n",
        "files = sorted_alphanumeric(files)\n",
        "for i in tqdm(files):    \n",
        "    if i == '855.jpg':\n",
        "        break\n",
        "    else:    \n",
        "        img = cv2.imread(path + '/'+i,1)\n",
        "        # open cv reads images in BGR format so we have to convert it to RGB\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        #resizing image\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = img.astype('float32') / 255.0\n",
        "        high_img.append(img_to_array(img))\n",
        "\n",
        "\n",
        "low_img = []\n",
        "path = '../input/image-super-resolution/dataset/Raw Data/low_res'\n",
        "files = os.listdir(path)\n",
        "files = sorted_alphanumeric(files)\n",
        "for i in tqdm(files):\n",
        "     if i == '855.jpg':\n",
        "        break\n",
        "     else: \n",
        "        img = cv2.imread(path + '/'+i,1)\n",
        "\n",
        "        #resizing image\n",
        "        img = cv2.resize(img, (SIZE, SIZE))\n",
        "        img = img.astype('float32') / 255.0\n",
        "        low_img.append(img_to_array(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4SHz6Lb8Lp4"
      },
      "source": [
        "## Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWzoXRmK8GCw"
      },
      "source": [
        "for i in range(4):\n",
        "    a = np.random.randint(0,855)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n",
        "    plt.imshow(high_img[a])\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n",
        "    plt.imshow(low_img[a])\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TleBISgF91w-"
      },
      "source": [
        "## Slicing and Reshaping Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt7W7UeZ8GAW"
      },
      "source": [
        "train_high_image = high_img[:700]\n",
        "train_low_image = low_img[:700]\n",
        "train_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\n",
        "train_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n",
        "\n",
        "validation_high_image = high_img[700:830]\n",
        "validation_low_image = low_img[700:830]\n",
        "validation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\n",
        "validation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n",
        "\n",
        "\n",
        "test_high_image = high_img[830:]\n",
        "test_low_image = low_img[830:]\n",
        "test_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))\n",
        "test_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n",
        "\n",
        "print(\"Shape of training images:\",train_high_image.shape)\n",
        "print(\"Shape of test images:\",test_high_image.shape)\n",
        "print(\"Shape of validation images:\",validation_high_image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EySJHOP-ZuP"
      },
      "source": [
        "## Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7701CQb8F-B"
      },
      "source": [
        "from keras import layers\n",
        "def down(filters , kernel_size, apply_batch_normalization = True):\n",
        "    downsample = tf.keras.models.Sequential()\n",
        "    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n",
        "    if apply_batch_normalization:\n",
        "        downsample.add(layers.BatchNormalization())\n",
        "    downsample.add(keras.layers.LeakyReLU())\n",
        "    return downsample\n",
        "\n",
        "\n",
        "def up(filters, kernel_size, dropout = False):\n",
        "    upsample = tf.keras.models.Sequential()\n",
        "    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n",
        "    if dropout:\n",
        "        upsample.dropout(0.2)\n",
        "    upsample.add(keras.layers.LeakyReLU())\n",
        "    return upsample\n",
        "\n",
        "def model():\n",
        "    inputs = layers.Input(shape= [SIZE,SIZE,3])\n",
        "    d1 = down(128,(3,3),False)(inputs)\n",
        "    d2 = down(128,(3,3),False)(d1)\n",
        "    d3 = down(256,(3,3),True)(d2)\n",
        "    d4 = down(512,(3,3),True)(d3)\n",
        "    \n",
        "    d5 = down(512,(3,3),True)(d4)\n",
        "    #upsampling\n",
        "    u1 = up(512,(3,3),False)(d5)\n",
        "    u1 = layers.concatenate([u1,d4])\n",
        "    u2 = up(256,(3,3),False)(u1)\n",
        "    u2 = layers.concatenate([u2,d3])\n",
        "    u3 = up(128,(3,3),False)(u2)\n",
        "    u3 = layers.concatenate([u3,d2])\n",
        "    u4 = up(128,(3,3),False)(u3)\n",
        "    u4 = layers.concatenate([u4,d1])\n",
        "    u5 = up(3,(3,3),False)(u4)\n",
        "    u5 = layers.concatenate([u5,inputs])\n",
        "    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=output)\n",
        "\n",
        "model = model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os1v8Dcb8F70"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              loss = 'mean_absolute_error', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmHJjRUz-tml"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVnP6s1a8F5e"
      },
      "source": [
        "model.fit(train_low_image, train_high_image, epochs = 7, batch_size = 1,\n",
        "          validation_data = (validation_low_image,validation_high_image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v_Z4zWP-zB2"
      },
      "source": [
        "## Prediction Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmFuPJ0B8F24"
      },
      "source": [
        "def plot_images(high,low,predicted):\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.title('High Image', color = 'green', fontsize = 20)\n",
        "    plt.imshow(high)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.title('Low Image ', color = 'black', fontsize = 20)\n",
        "    plt.imshow(low)\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n",
        "    plt.imshow(predicted)\n",
        "   \n",
        "    plt.show()\n",
        "\n",
        "for i in range(1,10):\n",
        "    \n",
        "    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n",
        "    plot_images(test_high_image[i],test_low_image[i],predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKelPa_v_ACv"
      },
      "source": [
        "## Saving model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRY91S4D8F0n"
      },
      "source": [
        "model.save(\"final_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
