{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11.12_Feature_Descriptor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AAPZKfdnXOiWgfmSNZPd-ZwWkl37Qw6C",
      "authorship_tag": "ABX9TyOEYj0A1ZZiVOj1wEPh+4L3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsaint31x/OpenCV_Python_Tutorial/blob/master/DIP/2021/%EA%B9%80%EA%B3%A0%EC%9D%80/11_12_Feature_Descriptor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajOkDv4GtPzd"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtzbdfGTyda1"
      },
      "source": [
        "img = cv2.imread('/content/drive/MyDrive/Classroom/3-2/ImageProcessing/Images/house.jpg')\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X70n12R6yjev"
      },
      "source": [
        "# Feature Descriptor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeVHDphCzYr_"
      },
      "source": [
        "# cv2. KeyPoint\n",
        "\n",
        "특징점 keypoint를 나타내는 opencv의 클래스\n",
        "다음과 같은 속성을 가짐\n",
        "- pt : keypoint좌표(x,y). float타입\n",
        "=> 어떤 한 점임(적게 사용-> locality올라감, aksgdl tkdydgkaus Ejfdjwla)\n",
        "- size : 의미있는 keypoint의 neibor의 반지름 \n",
        "=> 어떤 원으로 계산됨( neibor= 피쳐를 계산하는데 도움이 되는 영역, 같이 고려되는 영역, 이 영역안에서 계산이 됨_\n",
        "- angle : 특징점 방향(colock wise 이며, -1인 경우 아무 의미가 없음을 뜻함)\n",
        "- response : keypoint의 반응 강도\n",
        "- octave: keypoint가 발견된 image pyramid layer(이미지 피라미드 계층) \n",
        "=> 고해상도 ->저해상도, 저해상도 블러링 되는 방향으로 상위계측방향으로 layer가 쌓인다 할때 피쳐가 계산되는 특정 레이어가 있음(모든 레이어에 대해 피쳐를 구하는 게 아님) \n",
        "- class_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dc-Tvxe0rez"
      },
      "source": [
        "#  keypoints= detector.detect(img [,mask])\n",
        "\n",
        "parameters\n",
        "- img: 입력영상. binary scale\n",
        "- mask\n",
        "- keypoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ennPsod406C9"
      },
      "source": [
        "# cv2.draykeypoints (img, keypoints, outimg[,color[,flags]])\n",
        "=> util method\n",
        "- color = 원 색상\n",
        "feature를 그려주는 역할 \n",
        "\n",
        "제일 중요한 것은 keypoint의 위치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-I8ErKD1lWO"
      },
      "source": [
        "# Feature Descriptor 관련 openCV함수\n",
        "\n",
        "compute = keypoint를 알아서 내부에서 뽑음 -> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASYk4Mm92L9a"
      },
      "source": [
        "# SIFT 추출기 생성\n",
        "\n",
        "sift = cv2.xfeatres2d.SIFT_create() # sift라는 알고리즘으로 되어있는 detector가 생성된 것임\n",
        "# 들어가는 이미지 일반적으로 그레이스케일(gray), mask(None)를 안 씀 -> 이미지 전체를 다쓰겠다!\n",
        "keypoints, descriptor = sift.detectAndCompute(gray, None) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Eq5QF92Rek"
      },
      "source": [
        "# SURF 추출기 생성\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ds90hNu2T0_"
      },
      "source": [
        "# Oriented and Rotated BRIEF(ORB)\n",
        "\n",
        "기존의 BRIFT알고리즘에 orientation(방향)과 회전을 고려하도록 개선한 알고리즘.\n",
        "\n",
        "특허로 인해 사용에 제약이 많은 SIFT, SURF에 대한 \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuGvDWyz2XI6"
      },
      "source": [
        "# ORB\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9F_e_oW4z47",
        "outputId": "9a3b8131-397f-44a6-e31d-1b338844edad"
      },
      "source": [
        "# ORB 추출기 생성\n",
        "orb = cv2.ORB_create() # 위 방법은 cv2.xfeatres2d,에서 가져왔지만 orb는 자유롭기 때문에 안 씀.\n",
        "# 255 곱해줘야 함\n",
        "mask = np.ones_like(gray) #*255 \n",
        "# mask = np.zeros_like(gray)\n",
        "mask.astype(np.uint8)\n",
        "\n",
        "print(mask.dtype)\n",
        "# 키포인트 검출과 서술자 계산\n",
        "keypoints, descriptor = orb.detectAndCompute(img, None) # default\n",
        "# keypoints, descriptor = orb.detectAndCompute(img, mask)\n",
        "\n",
        "# 키 포인트 그리기 \n",
        "img_draw = cv2.drawKeypoints(img, keypoints, None, \n",
        "            flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI5DlqQw6kuw",
        "outputId": "7bcaffa1-f252-478c-87a2-d5881e9f331e"
      },
      "source": [
        "type(keypoints)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX0yiYpj6mKO",
        "outputId": "6dfe7e21-90e5-493d-cd08-71262d9caa8d"
      },
      "source": [
        "print(keypoints[0].pt) # x,y 좌표 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307.0, 32.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX9PqdHz7Hlm"
      },
      "source": [
        "# Feature Matching\n",
        "\n",
        "매칭되는 키포인트의 개수가 많을 수록, 두 영상이 유사하다 -> 두영상의 유사성의 정량지표로 사용 가능\n",
        "따라서 개수를 제시하는 것도 두 영상간 유사성을 입증하는 증거로 쓸 수 는 있음 , 단 논문에는 못 씀. (ssim같이 수치로 나오는 것도 아니고 개수는 절대적인 양이 아니기도 하고, 문제가 있음) '\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6SWIIv777Vm"
      },
      "source": [
        "# Hammig Distance\n",
        "\n",
        "openCV에서 제공하는 Hammig Distance는 다음과 같음\n",
        "\n",
        "- cv2. MORM_HAMMING : \n",
        "LO NORM과 거의 같은 방법(같으면 1이고 이를 모두 더하는 방식)\n",
        "- cv2. MORM_HAMMING2 :  \n",
        "한 놈과 그 옆에 있는 놈, 연달아서 맞아야 같다고 치는 방식 \n",
        "\n",
        "ORB의 경우, 임의 생성 좌표수가 3-4d일때는 cv2.NORM_HAMMING 이 권장됨\n",
        "SIFT, SURF는 CV2.NORM_L1 또는 CV2.NORM_L2가 권장됨 .\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbQ5Vf6O71oi"
      },
      "source": [
        "img1 = ('')\n",
        "img2 = ('')\n",
        "\n",
        "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# ORB로 featre descriptor 추출\n",
        "detector = cv2.ORB_create()\n",
        "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
        "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
        "\n",
        "# BF = BruteForce = 힘으로 밀어붙이는 알고리즘\n",
        "matcher = cv2.BFMatcher(cv2.MORM_HAMMING, crossCheck=True)\n",
        "\n",
        "# 최소 distance인 NN반환\n",
        "matches = matcher.match(desc1, desc2)\n",
        "\n",
        "# cross check = 양방향으로 체크\n",
        "\n",
        "# knn-match, k = 2, 최근접 이웃 2개를 distance가 작은 순으로 반환.\n",
        "# matches = matcher.knnMatch(desc1,desc2)\n",
        "\n",
        "res = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \n",
        "                      flags = cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "plt.figyre(figsize=(2*7,))\n",
        "print(f'matches:{}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4hZRMK4AM4b"
      },
      "source": [
        "img1=  cv2.imread('')\n",
        "img2 = cvw.imread('')\n",
        "gray1 = cv2.cvtColor(img1, cv2_COLOR_BGR2GRAY)\n",
        "gray2 = cv2.cvtColor(img2, cv2_COLOR_BGR2GRAY)\n",
        "\n",
        "# ORB로 feature descriptor 추출\n",
        "detector = cv2.ORB_CREATE()\n",
        "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
        "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
        "print(f'# of kp1: {len(kp1)} / # of kp2 : {len(kp2)}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}